<div class="markdown prose w-full break-words dark:prose-invert dark"><h3 data-start="0" data-end="57"><strong data-start="4" data-end="55">N-Grams in NLP (Natural Language Processing) ğŸš€</strong></h3>
<p data-start="58" data-end="206">N-grams are widely used in <strong data-start="85" data-end="168">language modeling, text prediction, speech recognition, and machine translation</strong>. Here are some NLP-specific examples:</p>
<hr data-start="208" data-end="211">
<h2 data-start="213" data-end="242"><strong data-start="216" data-end="242">1ï¸âƒ£ Word-Level N-Grams</strong></h2>
<p data-start="243" data-end="268">âœ… <strong data-start="245" data-end="266">Example Sentence:</strong></p>
<blockquote data-start="269" data-end="309">
<p data-start="271" data-end="309"><em data-start="271" data-end="309">"I love natural language processing"</em></p>
</blockquote>
<h3 data-start="311" data-end="334"><strong data-start="315" data-end="334">Bigrams (n = 2)</strong></h3>
<pre class="!overflow-visible" data-start="-end="418"><div class="contain-inline-size rounded-md border-[0.5px] border-token-border-medium relative bg-token-sidebar-surface-primary"><div class="flex items-center text-token-text-secondary px-4 py-2 text-xs font-sans justify-between h-9 bg-token-sidebar-surface-primary dark:bg-token-main-surface-secondary select-none rounded-t-[5px]">arduino</div><div class="sticky top-9"><div class="absolute bottom-0 right-0 flex h-9 items-center pr-2"><div class="flex items-center rounded bg-token-sidebar-surface-primary px-2 font-sans text-xs text-token-text-secondary dark:bg-token-main-surface-secondary"><span class="" data-state="closed"><button class="flex gap-1 items-center select-none px-4 py-1" aria-label="Copy"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-xs"><path fill-rule="evenodd" clip-rule="evenodd" d="M7 5C7 3.34315 8.34315 2 10 2H19C20.6569 2 22 3.34315 22 5V14C22 15.6569 20.6569 17 19 17H17V19C17 20.6569 15.6569 22 14 22H5C3.34315 22 2 20.6569 2 19V10C2 8.34315 3.34315 7 5 7H7V5ZM9 7H14C15.6569 7 17 8.34315 17 10V15H19C19.5523 15 20 14.5523 20 14V5C20 4.44772 19.5523 4 19 4H10C9.44772 4 9 4.44772 9 5V7ZM5 9C4.44772 9 4 9.44772 4 10V19C4 19.5523 4.44772 20 5 20H14C14.5523 20 15 19.5523 15 19V10C15 9.44772 14.5523 9 14 9H5Z" fill="currentColor"></path></svg>Copy</button></span><span class="" data-state="closed"><button class="flex select-none items-center gap-1 px-4 py-1"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-xs"><path d="M2.5 5.5C4.3 5.2 5.2 4 5.5 2.5C5.8 4 6.7 5.2 8.5 5.5C6.7 5.8 5.8 7 5.5 8.5C5.2 7 4.3 5.8 2.5 5.5Z" fill="currentColor" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M5.66282 16.5231L5.18413 19.3952C5.12203 19.7678 5.09098 19.9541 5.14876 20.0888C5.19933 20.2067 5.29328 20.3007 5.41118 20.3512C5.54589 20.409 5.73218 20.378 6.10476 20.3159L8.97693 19.8372C9.72813 19.712 10.1037 19.6494 10.4542 19.521C10.7652 19.407 11.0608 19.2549 11.3343 19.068C11.6425 18.8575 11.9118 18.5882 12.4503 18.0497L20 10.5C21.3807 9.11929 21.3807 6.88071 20 5.5C18.6193 4.11929 16.3807 4.11929 15 5.5L7.45026 13.0497C6.91175 13.5882 6.6425 13.8575 6.43197 14.1657C6.24513 14.4392 6.09299 14.7348 5.97903 15.0458C5.85062 15.3963 5.78802 15.7719 5.66282 16.5231Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.5 7L18.5 11" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg>Edit</button></span></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="!whitespace-pre"><span><span>(</span><span><span class="hljs-string">"I love"</span></span><span>), (</span><span><span class="hljs-string">"love natural"</span></span><span>), (</span><span><span class="hljs-string">"natural language"</span></span><span>), (</span><span><span class="hljs-string">"language processing"</span></span><span>)
</span></span></code></div></div></pre>
<p data-start="419" data-end="436">âœ… <strong data-start="421" data-end="434">Use Case:</strong></p>
<ul data-start="437" data-end="603">
<li data-start="437" data-end="527"><strong data-start="439" data-end="458">Text Prediction</strong>: If a model sees "I love", it can predict the next word ("natural").</li>
<li data-start="528" data-end="603"><strong data-start="530" data-end="550">Spell Correction</strong>: If someone types "I lvoe", it can suggest "I love".</li>
</ul>
<h3 data-start="605" data-end="629"><strong data-start="609" data-end="629">Trigrams (n = 3)</strong></h3>
<pre class="!overflow-visible" data-start="630" data-end="716"><div class="contain-inline-size rounded-md border-[0.5px] border-token-border-medium relative bg-token-sidebar-surface-primary"><div class="flex items-center text-token-text-secondary px-4 py-2 text-xs font-sans justify-between h-9 bg-token-sidebar-surface-primary dark:bg-token-main-surface-secondary select-none rounded-t-[5px]">arduino</div><div class="sticky top-9"><div class="absolutbottom-0 right-0 flex h-9 items-center pr-2"><div class="flex items-center rounded bg-token-sidebar-surface-primary px-2 font-sans text-xs text-token-text-secondary dark:bg-token-main-surface-secondary"><span class="" data-state="closed"><button class="flex gap-1 items-center select-none px-4 py-1" aria-label="Copy"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-xs"><path fill-rule="evenodd" clip-rule="evenodd" d="M7 5C7 3.34315 8.34315 2 10 2H19C20.6569 2 22 3.34315 22 5V14C22 15.6569 20.6569 17 19 17H17V19C17 20.6569 15.6569 22 14 22H5C3.34315 22 2 20.6569 2 19V10C2 8.34315 3.34315 7 5 7H7V5ZM9 7H14C15.6569 7 17 8.34315 17 10V15H19C19.5523 15 20 14.5523 20 14V5C20 4.44772 19.5523 4 19 4H10C9.44772 4 9 4.44772 9 5V7ZM5 9C4.44772 9 4 9.44772 4 10V19C4 19.5523 4.44772 20 5 20H14C14.5523 20 15 19.5523 15 19V10C15 9.44772 14.5523 9 14 9H5Z" fill="currentColor"></path></svg>Copy</button></span><span class="" data-state="closed"><button class="flex select-none items-center gap-1 px-4 py-1"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-xs"><path d="M2.5 5.5C4.3 5.2 5.2 4 5.5 2.5C5.8 4 6.7 5.2 8.5 5.5C6.7 5.8 5.8 7 5.5 8.5C5.2 7 4.3 5.8 2.5 5.5Z" fill="currentColor" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M5.66282 16.5231L5.18413 19.3952C5.12203 19.7678 5.09098 19.9541 5.14876 20.0888C5.19933 20.2067 5.29328 20.3007 5.41118 20.3512C5.54589 20.409 5.73218 20.378 6.10476 20.3159L8.97693 19.8372C9.72813 19.712 10.1037 19.6494 10.4542 19.521C10.7652 19.407 11.0608 19.2549 11.3343 19.068C11.6425 18.8575 11.9118 18.5882 12.4503 18.0497L20 10.5C21.3807 9.11929 21.3807 6.88071 20 5.5C18.6193 4.11929 16.3807 4.11929 15 5.5L7.45026 13.0497C6.91175 13.5882 6.6425 13.8575 6.43197 14.1657C6.24513 14.4392 6.09299 14.7348 5.97903 15.0458C5.85062 15.3963 5.78802 15.7719 5.66282 16.5231Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.5 7L18.5 11" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg>Edit</button></span></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="!whitespace-pre"><span><span>(</span><span><span class="hljs-string">"I love natural"</span></span><span>), (</span><span><span class="hljs-string">"love natural language"</span></span><span>), (</span><span><span class="hljs-string">"natural language processing"</span></span><span>)
</span></span></code></div></div></pre>
<p data-start="717" data-end="734">âœ… <strong data-start="719" data-end="732">Use Case:</strong></p>
<ul data-start="735" data-end="887">
<li data-start="735" data-end="820"><strong data-start="737" data-end="753">Autocomplete</strong>: A chatbot can predict "language processing" when given "natural".</li>
<li data-start="821" data-end="887"><strong data-start="823" data-end="846">Machine Translation</strong>: Helps capture local context in phrases.</li>
</ul>
<h3 datstart="889" data-end="933"><strong data-start="893" data-end="933">Higher Order N-Grams (n = 4, 5, ...)</strong></h3>
<pre class="!overflow-visible" data-start="934" data-end="1007"><div class="contain-inline-size rounded-md border-[0.5px] border-token-border-medium relative bg-token-sidebar-surface-primary"><div class="flex items-center text-token-text-secondary px-4 py-2 text-xs font-sans justify-between h-9 bg-token-sidebar-surface-primary dark:bg-token-main-surface-secondary select-none rounded-t-[5px]">arduino</div><div class="sticky top-9"><div class="absolute bottom-0 right-0 flex h-9 items-center pr-2"><div class="flex items-center rounded bg-token-sidebar-surface-primary px-2 font-sans text-xs text-token-text-secondary dark:bg-token-main-surface-secondary"><span class="" data-state="closed"><button class="flex gap-1 items-center select-none px-4 py-1" aria-label="Copy"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-xs"><path fill-rule="evenodd" clip-rule="evenodd" d="M7 5C7 3.34315 8.34315 2 10 2H19C20.6569 2 22 3.34315 22 5V14C22 15.6569 20.6569 17 19 17H17V19C17 20.6569 15.6569 22 14 22H5C3.34315 22 2 20.6569 2 19V10C2 8.34315 3.34315 7 5 7H7V5ZM9 7H14C15.6569 7 17 8.34315 17 10V15H19C19.5523 15 20 14.5523 20 14V5C20 4.44772 19.5523 4 19 4H10C9.44772 4 9 4.44772 9 5V7ZM5 9C4.44772 9 4 9.44772 4 10V19C4 19.5523 4.44772 20 5 20H14C14.5523 20 15 19.5523 15 19V10C15 9.44772 14.5523 9 14 9H5Z" fill="currentColor"></path></svg>Copy</button></span><span class="" data-state="closed"><button class="flex select-none items-center gap-1 px-4 py-1"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-xs"><path d="M2.5 5.5C4.3 5.2 5.2 4 5.5 2.5C5.8 4 6.7 5.2 8.5 5.5C6.7 5.8 5.8 7 5.5 8.5C5.2 7 4.3 5.8 2.5 5.5Z" fill="currentColor" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M5.66282 16.5231L5.18413 19.3952C5.12203 19.7678 5.09098 19.9541 5.14876 20.0888C5.19933 20.2067 5.29328 20.3007 5.41118 20.3512C5.54589 20.409 5.73218 20.378 6.10476 20.3159L8.97693 19.8372C9.72813 19.712 10.1037 19.6494 10.4542 19.521C10.7652 19.407 11.0608 19.2549 11.3343 19.068C11.6425 18.8575 11.9118 18.5882 12.4503 18.0497L20 10.5C21.3807 9.11929 21.3807 6.88071 20 5.5C18.6193 4.11929 16.3807 4.11929 15 5.5L7.45026 13.0497C6.91175 13.5882 6.6425 13.8575 6.43197 14.1657C6.24513 14.4392 6.09299 14.7348 5.97903 15.0458C5.85062 15.3963 5.78802 15.7719 5.66282 16.5231Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.5 7L18.5 11" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg>Edit</button></span></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="!whitespace-pre"><span><span>(</span><span><span class="hljs-string">"I love natural language"</span></span><span>), (</span><span><span class="hljs-string">"love natural language processing"</span></span><span>)
</span></span></code></div></div></pre>
<p data-start="1008" data-end="1025">âœ… <strong data-start="1010" data-end="1023">Use Case:</strong></p>
<ul data-start="1026" data-end="1163">
<li data-start="1026" data-end="1095"><strong data-start="1028" data-end="1060">Better Context Understanding</strong>: Captures more meaningful phrases.</li>
<li data-start="1096" data-end="1163"><strong data-start="1098" data-end="1120">Text Summarization</strong>: Identifies common multi-word expressions.</li>
</ul>
<hr data-start="1165" data-end="1168">
<h2 data-start="1170" data-end="1204"><strong data-start="1173" data-end="1204">2ï¸âƒ£ Character-Level N-Grams</strong></h2>
<p data-start="1205" data-end="1239">âœ… <strong data-start="1207" data-end="1224">Example Word:</strong> <code data-start="1225" data-end="1237">"language"</code></p>
<ul data-start="1240" data-end="1372">
<li data-start="1240" data-end="1305"><strong data-start="1242" data-end="1260">Bigrams (n=2):</strong> <code data-start="1261" data-end="1305">("la", "an", "n, "ua", "ag", "ge")</code></li>
<li data-start="1306" data-end="1372"><strong data-start="1308" data-end="1327">Trigrams (n=3):</strong> <code data-start="1328" data-end="1372">("lan", "ang", "ngu", "gua", "uag", "age")</code></li>
</ul>
<p data-start="1374" data-end="1392">âœ… <strong data-start="1376" data-end="1390">Use Cases:</strong></p>
<ul data-start="1393" data-end="1516">
<li data-start="1393" data-end="1453"><strong data-start="1395" data-end="1418">Spelling Correction</strong> â†’ "languge" â†’ Suggest "language"</li>
<li data-start="1454" data-end="1516"><strong data-start="1456" data-end="1474">Fuzzy Matching</strong> â†’ Searching <code data-start="1487" data-end="1495">"lang"</code> finds <code data-start="1502" data-end="1514">"language"</code></li>
</ul>
<pre class="!overflow-visible" data-start="1919" data-end="2133"><div class="contain-inline-size rounded-md border-[0.5px] border-token-border-medium relative bg-token-sidebar-surface-primary"><div class="overflow-y-auto p-4" dir="ltr"><code whitespace-pre language-python"><span><span>
</span></span></code></div></div></pre>
<hr data-start="2135" data-end="2138">
<h2 data-start="2140" data-end="2189"><strong data-start="2143" data-end="2189">&nbsp;Real-World NLP Applications of N-Grams</strong></h2>
<div class="overflow-x-auto contain-inline-size"><table data-start="2190" data-end="2705" node="[object Object]"><thead data-start="2190" data-end="2232"><tr data-start="2190" data-end="2232"><th data-start="2190" data-end="2208"><strong data-start="2192" data-end="2207">Application</strong></th><th data-start="2208" data-end="2232"><strong data-start="2210" data-end="2230">How N-Grams Help</strong></th></tr></thead><tbody data-start="2273" data-end="2705"><tr data-start="2273" data-end="2367"><td><strong data-start="2275" data-end="2317">Autocomplete (Google Search, Chatbots)</strong></td><td>Predicts next words based on bigrams/trigrams</td></tr><tr data-start="2368" data-end="2456"><td><strong data-start="2370" data-end="2419">Spell Checking &amp; OCR (Google Docs, Grammarly)&nbsp;&nbsp;</strong></td><td>Detects common spelling patterns</td></tr><tr data-start="2457" data-end="2551"><td><strong data-start="2459" data-end="2506">Speech Recognition (Siri, Google Assistant)</strong></td><td>Predicts words based on previous n-grams</td></tr><tr data-start="2552" data-end="2632"><td><strong data-start="2554" data-end="2596">Machine Translation (Google Translate)</strong></td><td>Helps preserve phrase structure</td></tr><tr data-start="2633" data-end="2705"><td><strong data-start="2635" data-end="2657">Sentiment Analysis</strong></td><td>Detects phrases like "not good", "very bad"</td></tr></tbody></table></div>
<hr data-start="2707" data-end="2710">
<h2 data-start="2712" data-end="2727"><span style="font-size: var(--bs-body-font-size); font-weight: var(--bs-body-font-weight); text-align: var(--bs-body-text-align);">ğŸ’¡ </span><span style="font-size: var(--bs-body-font-size); font-weight: var(--bs-body-font-weight); text-align: var(--bs-body-text-align);">ğspan><strong data-start="12" data-end="82" style="font-size: var(--bs-body-font-size); text-align: var(--bs-body-text-align);">N-grams are like a Markov chain but with "n" previous dependencies</strong><span style="font-size: var(--bs-body-font-size); font-weight: var(--bs-body-font-weight); text-align: var(--bs-body-text-align);">, whereas </span><strong data-start="92" data-end="166" style="font-size: var(--bs-body-font-size); text-align: var(--bs-body-text-align);">decoders (like in Transformers) depend on all previous words generated</strong><span style="font-size: var(--bs-body-font-size); font-weight: var(--bs-body-font-weight); text-align: var(--bs-body-text-align);">.</span></h2></div><div class="markdown prose w-full break-words dark:prose-invert dark">
<hr data-start="169" data-end="172">
<h3 data-start="174" data-end="236"><strong data-start="178" data-end="236">ğŸ”¹ Key Differences: N-Gram vs. Decoder in Transformers</strong></h3>
<div class="overflow-x-auto contain-inline-size"><table data-start=7" data-end="860" node="[object Object]"><thead data-start="237" data-end="305"><tr data-start="237" data-end="305"><th data-start="237" data-end="247">Feature</th><th data-start="247" data-end="266"><strong data-start="249" data-end="265">N-Gram Model</strong></th><th data-start="266" data-end="305"><strong data-start="268" data-end="303">Transformer Decoder (GPT, etc.)</strong></th></tr></thead><tbody data-start="370" data-end="860"><tr data-start="370" data-end="480"><td><strong data-start="372" data-end="386">Dependency</strong></td><td>Only on the last (n-1) words (Markov assumption)</td><td>On all previous words (self-attention)</td></tr><tr data-start="481" data-end="559"><td><strong data-start="483" data-end="493">Memory</strong></td><td>Fixed-size context window</td><td>Unlimited (depends on model size)</td></tr><tr data-start="560" data-end="629"><td><strong data-start="562" data-end="583">Context Awareness</strong></td><td>Short-range (local)</td><td>Long-range (global)</td></tr><tr data-start="630" data-end="760"><td><strong data-start="632" data-end="658">Example (Trigram: n=3)</strong></td><td><code data-start="661" data-end="676">"The cat sat"</code> â†’ predicts <code data-start="688" data-end="694">"on"</code></td><td><code data-start="697" data-end="719">"The cat sat on the"</code> â†’ uses full context to predict <code data-start="751" data-end="758">"mat"</code></td></tr><tr data-start="761" data-end="860"><td><strong data-start="763" data-end="777">Limitation</strong></td><td>Cannot model long-range dependencies well</td><td>Can handle entire sentence context</td></tr></tbody></table></div>
<hr data-start="862" data-end="865">
<h3 data-start="867" data-end="903"><strong data-start="871" data-end="903">1ï¸âƒ£ N-Gram as a Markov Model</strong></h3>
<ul data-start="904" data-end="1073">
<li data-start="904" data-end="987">A <strong data-start="908" data-end="930">bigram model (n=2)</strong> assumes <strong data-start="939" data-end="986">each word depends only on the previous word</strong>.</lita-start="988" data-end="1073">A <strong data-start="992" data-end="1015">trigram model (n=3)</strong> assumes <strong data-start="1024" data-end="1072">each word depends only on the last two words</strong>.</li>
</ul>
<p data-start="1075" data-end="1229">ğŸ’¡ <strong data-start="1078" data-end="1105">Example (Trigram Model)</strong><br data-start="1105" data-end="1108">
If we have:<br data-start="1119" data-end="1122">
<code data-start="1122" data-end="1149">"I love machine learning"</code><br data-start="1149" data-end="1152">
A <strong data-start="1154" data-end="1171">trigram model</strong> predicts the next word using <strong data-start="1201" data-end="1228">only the last two words</strong>:</p>
<pre class="!overflow-visible" data-start="1230" data-end="1301"><div class="contain-inline-size rounded-md border-[0.5px] border-token-border-medium relative bg-token-sidebar-surface-primary"><div class="flex items-center text-token-text-secondary px-4 py-2 text-xs font-sans justify-between h-9 bg-token-sidebarrface-primary dark:bg-token-main-surface-secondary select-none rounded-t-[5px]">less</div><div class="sticky top-9"><div class="absolute bottom-0 right-0 flex h-9 items-center pr-2"><div class="flex items-center rounded bg-token-sidebar-surface-primary px-2 font-sans text-xs text-token-text-secondary dark:bg-token-main-surface-secondary"><span class="" data-state="closed"><button class="flex gap-1 items-center select-none px-4 py-1" aria-label="Copy"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-xs"><path fill-rule="evenodd" clip-rule="evenodd" d="M7 5C7 3.34315 8.34315 2 10 2H19C20.6569 2 22 3.34315 22 5V14C22 15.6569 20.6569 17 19 17H17V19C17 20.6569 15.6569 22 14 22H5C3.34315 22 2 20.6569 2 19V10C2 8.34315 3.34315 7 5 7H7V5ZM9 7H14C15.6569 7 17 8.34315 17 10V15H19C19.5523 15 20 14.5523 20 14V5C20 4.44772 19.5523 4 19 4H10C9.44772 4 9 4.44772 9 5V7ZM5 9C4.44772 9 4 9.44772 4 10V19C4 19.5523 4.44772 20 5 20H14C14.5523 20 15 19.5523 15 19V10C15 9.44772 14.5523 9 14 9H5Z" fill="currentColor"></path></svg>Copy</button></span><span class="" data-state="closed"><button class="flex select-none items-center gap-1 px-4 py-1"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-xs"><path d="M2.5 5.5C4.3 5.2 5.2 4 5.5 2.5C5.8 4 6.7 5.2 8.5 5.5C6.7 5.8 5.8 7 5.5 8.5C5.2 7 4.3 5.8 2.5 5.5Z" fill="currentColor" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M5.66282 16.5231L5.18413 19.3952C5.12203 19.7678 5.09098 19.9541 5.14876 20.0888C5.19933 20.2067 5.29328 20.3007 5.41118 20.3512C5.54589 20.409 5.73218 20.378 6.10476 20.3159L8.97693 19.8372C9.72813 19.712 10.1037 19.6494 10.4542 19.521C10.7652 19.407 11.0608 19.2549 11.3343 19.068C11.6425 18.8575 11.9118 18.5882 12.4503 18.0497L20 10.5C21.3807 9.11929 21.3807 6.88071 20 5.5C18.6193 4.11929 16.3807 4.11929 15 5.5L7.45026 13.0497C6.91175 13.5882 6.6425 13.8575 6.43197 14.1657C6.24513 14.4392 6.09299 14.7348 5.97903 15.0458C5.85062 15.3963 5.78802 15.7719 5.66282 16.5231Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.5 7L18.5 11" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg>Edit</button></span></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="!whitespace-pre"><span><span><span class="hljs-selector-tag">P</span></span><span>(</span><span><span class="hljs-string">"learning"</span></span><span> | </span><span><span class="hljs-string">"machine"</span></span><span>)
</span><span><span class="hljs-selector-tag">P</span></span><span>(</span><span><span class="hljs-string">"machine"</span></span><span> | </span><span><span class="hljs-string">"love"</span></span><span>)
</span><span><span class="hljs-selector-tag">P</span></span><span>(</span><span><span class="hljs-string">"love"</span></span><span> | </span><span><span class="hljs-string">"I"</span></span><span>)
</span></span></code></div></div></pre>
<p data-start="1302" data-end="1369">ğŸš¨ <strong data-start="1305" data-end="1319">Limitation</strong>: It <strong data-start="1324" data-end="1335">forgets</strong> words beyond the last "n" tokens.</p>
<hr data-start="1371" data-end="1374">
<h3 data-start="1376" data-end="1424"><strong data-start="1380" data-end="1424">2ï¸âƒ£ Transformer Decoder (Self-Attention)</strong></h3>
<ul data-start="1425" data-end="1608">
<li data-start="1425" data-end="1478">Uses <strong data-start="1432" data-end="1454">all previous words</strong>, not just the last "n".</li>
<li data-start="1479" data-end="1535">Uses <strong data-start="1486" data-end="1511">positional embeddings</strong> to maintain word order.</li>
<li data-start="1536" data-end="1608"><strong data-start="1538" data-end="1566">Self-attention mechanism</strong> computes relationships between all words.</li>
</ul>
<p data-start="1610" data-end="1748">ğŸ’¡ <strong data-start="1613" data-end="1662">Example (GPT-Style Autoregressive Generation)</strong>
I<br data-start="1674" data-end="1677">
<code data-start="1677" data-end="1703">"The cat sat on the mat"</code><br data-start="1703" data-end="1706">
The <strong data-start="1710" data-end="1721">decoder</strong> predicts <code data-start="1731" data-end="1738">"mat"</code> based on:</p>
<pre class="!overflow-visible" data-start="1749" data-end="1788"><div class="contain-inline-size rounded-md border-[0.5px] border-token-border-medium relative bg-token-sidebar-surface-primary"><div class="flex items-center text-token-text-secondary px-4 py-2 text-xs font-sans justify-between h-9 bg-token-sidebar-surface-primary dark:bg-token-main-surface-secondary select-none rounded-t-[5px]">less</div><div class="sticky top-9"><div class="absolute bottom-0 right-0 flex h-9 items-center pr-2"><div class="flex items-center rounded bg-token-sidebar-surface-primary px-2 font-sans text-xs text-token-text-secondary dark:bg-token-main-surface-secondary"><span class="" data-state="closed"><button class="flex gap-1 items-center select-none px-4 py-1" aria-label="Copy"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-xs"><path fill-rule="evenodd" clip-rule="evenodd" d="M7 5C7 3.34315 8.34315 2 10 2H19C20.6569 2 22 3.34315 22 5V14C22 15.6569 20.6569 17 19 17H17V19C17 20.6569 15.6569 22 14 22H5C3.34315 22 2 20.6569 2 19V10C2 8.34315 3.34315 7 5 7H7V5ZM9 7H14C15.6569 7 17 8.34315 17 10V15H19C19.5523 15 20 14.5523 20 14V5C20 4.44772 19.5523 4 19 4H10C9.44772 4 9 4.44772 9 5V7ZM5 9C4.44772 9 4 9.44772 4 10V19C4 19.5523 4.44772 20 5 20H14C14.5523 20 15 19.5523 15 19V10C15 9.44772 14.5523 9 14 9H5Z" fill="currentColor"></path></svg>Copy</button></span><span class="" data-state="closed"><button class="flex select-none items-center gap-1 px-4 py-1"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-xs"><path d="M2.5 5.5C4.3 5.2 5.2 4 5.5 2.5C5.8 4 6.7 5.2 8.5 5.5C6.7 5.8 5.8 7 5.5 8.5C5.2 7 4.3 5.8 2.5 5.5Z" fill="currentColor" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path><path d="M5.66282 16.5231L5.18413 19.3952C5.12203 19.7678 5.09098 19.9541 5.14876 20.0888C5.19933 20.2067 5.29328 20.3007 5.41118 20.3512C5.54589 20.409 5.73218 20.378 6.10476 20.3159L8.97693 19.8372C9.72813 19.712 10.1037 19.6494 10.4542 19.521C10.7652 19.407 11.0608 19.2549 11.3343 19.068C11.6425 18.8575 11.9118 18.5882 12.4503 18.0497L20 10.5C21.3807 9.11929 21.3807 6.88071 20 5.5C18.6193 4.11929 16.3807 4.11929 15 5.5L7.45026 13.0497C6.91175 13.5882 6.6425 13.8575 6.43197 14.1657C6.24513 14.4392 6.09299 14.7348 5.97903 15.0458C5.85062 15.3963 5.78802 15.7719 5.66282 16.5231Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.5 7L18.5 11" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg>Edit</button></span></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="!whitespace-pre"><span><span><span class="hljs-selector-tag">P</span></span><span>(</span><span><span class="hljs-string">"mat"</span></span><span> | </span><span><span class="hljs-string">"The cat sat on the"</span></span><span>)
</span></span></code></div></div></pre>
<p data-start="1789" data-end="1840">ğŸš€ <strong data-start="1792" data-end="1805">Advantage</strong>: Captures long-range dependencies.</p>
<hr data-start="1842" data-end="1845">
<h3 data-start="1847" data-end="1863"><strong data-start="1851" data-end="1863">ğŸ”¹ TL;DR</strong></h3>
<p data-start="1864" data-end="2151" data-is-only-node="" data-is-last-node="">âœ… <strong data-start="1866" data-end="1934">N-Grams = Limited context (Markov assumption, fixed n-1 memory).</strong><br data-start="1934" data-end="1937">
âœ… <strong data-start="1939" data-end="2039">Decoder (GPT/BART) = Uses self-attention to see all past words, enabling long-term dependencies.</strong><br data-start="2039" data-end="2042">
âœ… <strong data-start="2044" data-end="2148">N-Grams work well for simple models, but deep learnrmers) outperforms them in NLP tasks.</strong> ğŸš€</p></div>