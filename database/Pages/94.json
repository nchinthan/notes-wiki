{
    "title": "polling in main eventloop",
    "html": "<div class=\"markdown prose w-full break-words dark:prose-invert dark\"><h3 data-start=\"0\" data-end=\"62\" class=\"\"><strong data-start=\"4\" data-end=\"60\">Event Loop in a Server: Single vs. Multiple Threads?</strong></h3>\n<p data-start=\"64\" data-end=\"324\" class=\"\">Yes, in an <strong data-start=\"75\" data-end=\"98\">event-driven server</strong>, there is usually a <strong data-start=\"119\" data-end=\"138\">main event loop</strong> that listens for new requests. However, whether the server uses <strong data-start=\"203\" data-end=\"263\">one thread, multiple threads, or even multiple processes</strong> depends on the <strong data-start=\"279\" data-end=\"296\">design choice</strong> and <strong data-start=\"301\" data-end=\"321\">type of workload</strong>.</p>\n<hr data-start=\"326\" data-end=\"329\" class=\"\" style=\"\">\n<h3 data-start=\"331\" data-end=\"393\" class=\"\"><strong data-start=\"335\" data-end=\"393\">1Ô∏è‚É£ Single-Threaded Event Loop (Node.js, Nginx, Redis)</strong></h3>\n<ul data-start=\"394\" data-end=\"1080\">\n<li data-start=\"394\" data-end=\"710\" class=\"\" style=\"\">\n<p data-start=\"396\" data-end=\"415\" class=\"\"><strong data-start=\"396\" data-end=\"413\">How it works?</strong></p>\n<ul data-start=\"418\" data-end=\"710\">\n<li data-start=\"418\" data-end=\"463\" class=\"\" style=\"\">\n<p data-start=\"420\" data-end=\"463\" class=\"\">A <strong data-start=\"422\" data-end=\"439\">single thread</strong> runs an <strong data-start=\"448\" data-end=\"462\">event loop</strong>.</p>\n</li>\n<li data-start=\"466\" data-end=\"554\" class=\"\" style=\"\">\n<p data-start=\"468\" data-end=\"554\" class=\"\">Uses <strong data-start=\"473\" data-end=\"487\"><code data-start=\"475\" data-end=\"485\">select()</code></strong>, <code data-start=\"489\" data-end=\"497\">poll()</code>, <code data-start=\"499\" data-end=\"508\">epoll()</code>, or <code data-start=\"513\" data-end=\"523\">kqueue()</code> to monitor multiple sockets.</p>\n</li>\n<li data-start=\"557\" data-end=\"631\" class=\"\" style=\"\">\n<p data-start=\"559\" data-end=\"631\" class=\"\"><strong data-start=\"559\" data-end=\"579\">Non-blocking I/O</strong> ensures that the thread never gets stuck waiting.</p>\n</li>\n<li data-start=\"634\" data-end=\"710\" class=\"\" style=\"\">\n<p data-start=\"636\" data-end=\"710\" class=\"\">Callbacks are triggered when an event occurs (e.g., a new HTTP request).</p>\n</li>\n</ul>\n</li>\n<li data-start=\"712\" data-end=\"763\" class=\"\" style=\"\">\n<p data-start=\"714\" data-end=\"763\" class=\"\"><strong data-start=\"714\" data-end=\"726\">Example:</strong> Node.js, Nginx (by default), Redis</p>\n</li>\n<li data-start=\"764\" data-end=\"922\" class=\"\" style=\"\">\n<p data-start=\"766\" data-end=\"922\" class=\"\"><strong data-start=\"766\" data-end=\"775\">Pros:</strong>\n‚úÖ Simple, lightweight, and easy to scale with <strong data-start=\"824\" data-end=\"844\">async operations</strong>.<br data-start=\"845\" data-end=\"848\">\n‚úÖ Avoids thread synchronization issues (e.g., race conditions, locks).</p>\n</li>\n<li data-start=\"923\" data-end=\"1080\" class=\"\" style=\"\">\n<p data-start=\"925\" data-end=\"1080\" class=\"\"><strong data-start=\"925\" data-end=\"934\">Cons:</strong><br data-start=\"934\" data-end=\"937\">\n‚ùå <strong data-start=\"941\" data-end=\"981\">CPU-bound tasks block the event loop</strong> (e.g., large computations).<br data-start=\"1009\" data-end=\"1012\">\n‚ùå Not ideal for multi-core CPUs since it only uses <strong data-start=\"1065\" data-end=\"1077\">one core</strong>.</p>\n</li>\n</ul>\n<hr data-start=\"1082\" data-end=\"1085\" class=\"\" style=\"\">\n<h3 data-start=\"1087\" data-end=\"1157\" class=\"\"><strong data-start=\"1091\" data-end=\"1157\">2Ô∏è‚É£ Multi-Threaded Event Loop (Java NIO, Netty, Apache, MySQL)</strong></h3>\n<ul data-start=\"1158\" data-end=\"1715\">\n<li data-start=\"1158\" data-end=\"1352\" class=\"\" style=\"\">\n<p data-start=\"1160\" data-end=\"1179\" class=\"\"><strong data-start=\"1160\" data-end=\"1177\">How it works?</strong></p>\n<ul data-start=\"1182\" data-end=\"1352\">\n<li data-start=\"1182\" data-end=\"1268\" class=\"\" style=\"\">\n<p data-start=\"1184\" data-end=\"1268\" class=\"\">A <strong data-start=\"1186\" data-end=\"1205\">main event loop</strong> listens for new connections (using <code data-start=\"1241\" data-end=\"1251\">select()</code> or <code data-start=\"1255\" data-end=\"1264\">epoll()</code>).</p>\n</li>\n<li data-start=\"1271\" data-end=\"1352\" class=\"\" style=\"\">\n<p data-start=\"1273\" data-end=\"1352\" class=\"\">It then hands off each connection to a <strong data-start=\"1312\" data-end=\"1334\">worker thread pool</strong> for processing.</p>\n</li>\n</ul>\n</li>\n<li data-start=\"1354\" data-end=\"1447\" class=\"\" style=\"\">\n<p data-start=\"1356\" data-end=\"1447\" class=\"\"><strong data-start=\"1356\" data-end=\"1368\">Example:</strong> Apache HTTP Server (prefork or worker mode), Java NIO (Netty, Tomcat), MySQL</p>\n</li>\n<li data-start=\"1448\" data-end=\"1578\" class=\"\" style=\"\">\n<p data-start=\"1450\" data-end=\"1578\" class=\"\"><strong data-start=\"1450\" data-end=\"1459\">Pros:</strong><br data-start=\"1459\" data-end=\"1462\">\n‚úÖ Uses multiple CPU cores efficiently.<br data-start=\"1502\" data-end=\"1505\">\n‚úÖ Can handle <strong data-start=\"1520\" data-end=\"1543\">blocking operations</strong> (e.g., database queries) better.</p>\n</li>\n<li data-start=\"1579\" data-end=\"1715\" class=\"\" style=\"\">\n<p data-start=\"1581\" data-end=\"1715\" class=\"\"><strong data-start=\"1581\" data-end=\"1590\">Cons:</strong><br data-start=\"1590\" data-end=\"1593\">\n‚ùå More complex than a single-threaded model.<br data-start=\"1639\" data-end=\"1642\">\n‚ùå Requires <strong data-start=\"1655\" data-end=\"1681\">thread synchronization</strong> (mutexes, condition variables).</p>\n</li>\n</ul>\n<hr data-start=\"1717\" data-end=\"1720\" class=\"\" style=\"\">\n<h3 data-start=\"1722\" data-end=\"1811\" class=\"\"><strong data-start=\"1726\" data-end=\"1811\">3Ô∏è‚É£ Multi-Process Server Model (Apache prefork, PostgreSQL, Nginx in worker mode)</strong></h3>\n<ul data-start=\"1812\" data-end=\"2403\">\n<li data-start=\"1812\" data-end=\"2046\" class=\"\" style=\"\">\n<p data-start=\"1814\" data-end=\"1833\" class=\"\"><strong data-start=\"1814\" data-end=\"1831\">How it works?</strong></p>\n<ul data-start=\"1836\" data-end=\"2046\">\n<li data-start=\"1836\" data-end=\"1912\" class=\"\" style=\"\">\n<p data-start=\"1838\" data-end=\"1912\" class=\"\">Instead of threads, the server forks multiple <strong data-start=\"1884\" data-end=\"1909\">independent processes</strong>.</p>\n</li>\n<li data-start=\"1915\" data-end=\"1986\" class=\"\" style=\"\">\n<p data-start=\"1917\" data-end=\"1986\" class=\"\">Each process handles a separate request <strong data-start=\"1957\" data-end=\"1983\">without sharing memory</strong>.</p>\n</li>\n<li data-start=\"1989\" data-end=\"2046\" class=\"\" style=\"\">\n<p data-start=\"1991\" data-end=\"2046\" class=\"\">Uses <strong data-start=\"1996\" data-end=\"2033\">IPC (Inter-Process Communication)</strong> if needed.</p>\n</li>\n</ul>\n</li>\n<li data-start=\"2048\" data-end=\"2121\" class=\"\" style=\"\">\n<p data-start=\"2050\" data-end=\"2121\" class=\"\"><strong data-start=\"2050\" data-end=\"2062\">Example:</strong> Apache (prefork mode), PostgreSQL, old-style CGI scripts</p>\n</li>\n<li data-start=\"2122\" data-end=\"2265\" class=\"\" style=\"\">\n<p data-start=\"2124\" data-end=\"2265\" class=\"\"><strong data-start=\"2124\" data-end=\"2133\">Pros:</strong><br data-start=\"2133\" data-end=\"2136\">\n‚úÖ Each process is <strong data-start=\"2156\" data-end=\"2168\">isolated</strong> ‚Üí a crash in one process does not affect others.<br data-start=\"2217\" data-end=\"2220\">\n‚úÖ No need for <strong data-start=\"2236\" data-end=\"2262\">thread synchronization</strong>.</p>\n</li>\n<li data-start=\"2266\" data-end=\"2403\" class=\"\" style=\"\">\n<p data-start=\"2268\" data-end=\"2403\" class=\"\"><strong data-start=\"2268\" data-end=\"2277\">Cons:</strong><br data-start=\"2277\" data-end=\"2280\">\n‚ùå <strong data-start=\"2284\" data-end=\"2305\">High memory usage</strong> (each process has its own memory space).<br data-start=\"2346\" data-end=\"2349\">\n‚ùå <strong data-start=\"2353\" data-end=\"2380\">Slower process creation</strong> compared to threads.</p>\n</li>\n</ul>\n<hr data-start=\"2405\" data-end=\"2408\" class=\"\" style=\"\">\n<h3 data-start=\"2410\" data-end=\"2440\" class=\"\"><strong data-start=\"2414\" data-end=\"2440\">Which Model is Better?</strong></h3>\n<div class=\"overflow-x-auto contain-inline-size\"><table data-start=\"2441\" data-end=\"2768\" node=\"[object Object]\"><thead data-start=\"2441\" data-end=\"2479\"><tr data-start=\"2441\" data-end=\"2479\"><th data-start=\"2441\" data-end=\"2449\">Model</th><th data-start=\"2449\" data-end=\"2460\">Best For</th><th data-start=\"2460\" data-end=\"2479\">Example Servers</th></tr></thead><tbody data-start=\"2521\" data-end=\"2768\"><tr data-start=\"2521\" data-end=\"2598\"><td><strong data-start=\"2523\" data-end=\"2542\">Single-Threaded</strong></td><td>High I/O, low CPU</td><td>Node.js, Nginx (default), Redis</td></tr><tr data-start=\"2599\" data-end=\"2688\"><td><strong data-start=\"2601\" data-end=\"2619\">Multi-Threaded</strong></td><td>CPU-heavy tasks</td><td>Apache (worker mode), Java NIO (Netty, Tomcat)</td></tr><tr data-start=\"2689\" data-end=\"2768\"><td><strong data-start=\"2691\" data-end=\"2708\">Multi-Process</strong></td><td>High isolation, security</td><td>Apache (prefork), PostgreSQL</td></tr></tbody></table></div>\n<hr data-start=\"2770\" data-end=\"2773\" class=\"\" style=\"\">\n<h3 data-start=\"2775\" data-end=\"2793\" class=\"\"><strong data-start=\"2779\" data-end=\"2793\">Conclusion</strong></h3>\n<p data-start=\"2794\" data-end=\"2891\" class=\"\">Most modern <strong data-start=\"2806\" data-end=\"2834\">high-performance servers</strong> (like Nginx, Apache, Node.js) use a <strong data-start=\"2871\" data-end=\"2890\">hybrid approach</strong>:</p>\n<ul data-start=\"2892\" data-end=\"3058\">\n<li data-start=\"2892\" data-end=\"2967\" class=\"\" style=\"\">\n<p data-start=\"2894\" data-end=\"2967\" class=\"\"><strong data-start=\"2894\" data-end=\"2912\">One event loop</strong> (single-threaded) for <strong data-start=\"2935\" data-end=\"2964\">accepting new connections</strong>.</p>\n</li>\n<li data-start=\"2968\" data-end=\"3058\" class=\"\" style=\"\">\n<p data-start=\"2970\" data-end=\"3058\" class=\"\"><strong data-start=\"2970\" data-end=\"2997\">Multiple worker threads</strong> (or processes) to handle actual requests <strong data-start=\"3039\" data-end=\"3055\">concurrently</strong>.</p>\n</li>\n</ul>\n<p data-start=\"3060\" data-end=\"3200\" class=\"\">For example, <strong data-start=\"3073\" data-end=\"3113\">Nginx uses multiple worker processes</strong>, while <strong data-start=\"3121\" data-end=\"3197\">Apache can be configured for either multi-threaded or multi-process mode</strong>.</p>\n<p data-start=\"3202\" data-end=\"3284\" class=\"\">Would you like an example of how a <strong data-start=\"3237\" data-end=\"3274\">multi-threaded event-based server</strong> works? üöÄ</p></div>"
}