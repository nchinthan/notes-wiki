{
    "title": "stationary distribution",
    "html": "<div class=\"markdown prose w-full break-words dark:prose-invert dark\"><p data-start=\"0\" data-end=\"159\" class=\"\">This statement is about the <strong data-start=\"28\" data-end=\"55\">stationary distribution</strong> of a <strong data-start=\"61\" data-end=\"77\">Markov chain</strong> and why a strongly connected (irreducible) Markov chain guarantees its existence.</p>\n<h3 data-start=\"161\" data-end=\"186\" class=\"\"><strong data-start=\"165\" data-end=\"186\">Breaking it Down:</strong></h3>\n<ol data-start=\"187\" data-end=\"1385\">\n<li data-start=\"187\" data-end=\"470\" class=\"\" style=\"\">\n<p data-start=\"190\" data-end=\"233\" class=\"\"><strong data-start=\"190\" data-end=\"231\">Strong Connectivity (Irreducibility):</strong></p>\n<ul data-start=\"237\" data-end=\"470\">\n<li data-start=\"237\" data-end=\"398\" class=\"\" style=\"\">\n<p data-start=\"239\" data-end=\"398\" class=\"\">A Markov chain is <strong data-start=\"257\" data-end=\"279\">strongly connected</strong> if every state (node) can be reached from any other state with a nonzero probability in some finite number of steps.</p>\n</li>\n<li data-start=\"402\" data-end=\"470\" class=\"\" style=\"\">\n<p data-start=\"404\" data-end=\"470\" class=\"\">In Markov chain terms, this property is called <strong data-start=\"451\" data-end=\"469\">irreducibility</strong>.</p>\n</li>\n</ul>\n</li>\n<li data-start=\"472\" data-end=\"929\" class=\"\" style=\"\">\n<p data-start=\"475\" data-end=\"505\" class=\"\"><strong data-start=\"475\" data-end=\"503\">Stationary Distribution:</strong></p>\n<ul data-start=\"509\" data-end=\"929\">\n<li data-start=\"509\" data-end=\"681\" class=\"\" style=\"\">\n<p data-start=\"511\" data-end=\"681\" class=\"\">A <strong data-start=\"513\" data-end=\"540\">stationary distribution</strong> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Ï€</mi></mrow><annotation encoding=\"application/x-tex\">\\pi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height: 0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right: 0.03588em;\">Ï€</span></span></span></span> is a probability distribution over the states such that if the Markov chain starts in this distribution, it remains in it forever.</p>\n</li>\n<li data-start=\"685\" data-end=\"929\" class=\"\" style=\"\">\n<p data-start=\"687\" data-end=\"808\" class=\"\">Mathematically, if <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi></mrow><annotation encoding=\"application/x-tex\">P</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height: 0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right: 0.13889em;\">P</span></span></span></span> is the transition matrix of the Markov chain, the stationary distribution <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Ï€</mi></mrow><annotation encoding=\"application/x-tex\">\\pi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height: 0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right: 0.03588em;\">Ï€</span></span></span></span> satisfies:</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>Ï€</mi><mi>P</mi><mo>=</mo><mi>Ï€</mi></mrow><annotation encoding=\"application/x-tex\">\\pi P = \\pi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height: 0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right: 0.03588em;\">Ï€</span><span class=\"mord mathnormal\" style=\"margin-right: 0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right: 0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right: 0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height: 0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right: 0.03588em;\">Ï€</span></span></span></span></span>\n<p data-start=\"847\" data-end=\"929\" class=\"\">meaning that the probabilities do not change after applying the transition matrix.</p>\n</li>\n</ul>\n</li>\n<li data-start=\"931\" data-end=\"1385\" class=\"\" style=\"\">\n<p data-start=\"934\" data-end=\"981\" class=\"\"><strong data-start=\"934\" data-end=\"979\">Why Does a Stationary Distribution Exist?</strong></p>\n<ul data-start=\"985\" data-end=\"1385\">\n<li data-start=\"985\" data-end=\"1205\" class=\"\" style=\"\">\n<p data-start=\"987\" data-end=\"1205\" class=\"\">If a Markov chain is <strong data-start=\"1008\" data-end=\"1023\">irreducible</strong> (strongly connected) and <strong data-start=\"1049\" data-end=\"1062\">aperiodic</strong> (i.e., it doesnâ€™t get stuck in cycles), then <strong data-start=\"1108\" data-end=\"1157\">there exists a unique stationary distribution</strong> that the Markov chain converges to over time.</p>\n</li>\n<li data-start=\"1209\" data-end=\"1385\" class=\"\" style=\"\">\n<p data-start=\"1211\" data-end=\"1385\" class=\"\">This means that after <strong data-start=\"1233\" data-end=\"1272\">a sufficiently long number of steps</strong>, the probability distribution of the states settles into a fixed distribution, regardless of the starting state.</p>\n</li>\n</ul>\n</li>\n</ol>\n<h3 data-start=\"1387\" data-end=\"1432\" class=\"\"><strong data-start=\"1391\" data-end=\"1432\">Conclusion (What the Statement Means)</strong></h3>\n<p data-start=\"1433\" data-end=\"1705\" class=\"\">Since the Markov chain in the problem is strongly connected, it is <strong data-start=\"1500\" data-end=\"1548\">guaranteed to have a stationary distribution</strong>.<br data-start=\"1549\" data-end=\"1552\">\nThus, after a very long random walk, the probability of being in any given state will stabilize and converge to this stationary distribution <strong data-start=\"1693\" data-end=\"1704\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Ï€</mi></mrow><annotation encoding=\"application/x-tex\">\\pi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height: 0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right: 0.03588em;\">Ï€</span></span></span></span></strong>.</p>\n<p data-start=\"1707\" data-end=\"1904\" class=\"\">This is a fundamental property used in many applications, like <strong data-start=\"1770\" data-end=\"1782\">PageRank</strong>, where web pages are treated as states in a Markov chain, and the stationary distribution determines their importance. ðŸš€</p></div>"
}